# -*- coding: utf-8 -*-
"""Recomendation System - Nibroos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19AEY_kZMephEgndtMi3tt1rM-OVK1tfg
"""

!pip install scikit-surprise

"""# Import Package dan Library
* Mengimpor library yang dibutuhkan untuk analisis data dan machine learning.
* Pandas dan NumPy untuk manipulasi data, Scikit-learn untuk model machine learning, Matplotlib dan Seaborn untuk visualisasi data.
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split

"""# Load Data
* Crawling data dari github
* Dataset akan dimuat ke dalam variabel 'df' sebagai Pandas DataFrame.
"""

urls = [
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Action.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Adventure.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Animation.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Comedy.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Crime.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Drama.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Fantasy.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Horror.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Mystery.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Music.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Romance.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Sci-Fi.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/Thriller.csv',
    'https://raw.githubusercontent.com/Rahmathidayat4299/dataset-movie-recomendation/master/War.csv'
]

# Muat semua dataset dan gabungkan menjadi satu
dataframes = [pd.read_csv(url) for url in urls]
datafilm = pd.concat(dataframes, ignore_index=True)

# Cek hasil gabungan
print(datafilm.head())

# Simpan dataset gabungan ke file CSV
datafilm.to_csv('movies.csv', index=False)

file_path = '/content/movies.csv'
df = pd.read_csv(file_path)

"""# Data Understanding

### Cek ukuran data dan tipe data: Untuk memahami dimensi dan karakteristik dasar dataset. Ukuran dataset (jumlah baris dan kolom) memberikan gambaran tentang jumlah data yang akan diproses. Tipe data (misalnya, numerik, kategorikal, teks) menentukan jenis analisis dan pemrosesan yang dapat dilakukan.
"""

df.info()

"""### Cek missing value: Untuk mengidentifikasi data yang hilang atau tidak terisi pada setiap kolom dalam dataset. Data yang hilang dapat mengganggu proses analisis dan pemodelan machine learning."""

print("\nCek missing values:")
print(df.isnull().sum())

"""### Cek duplikasi data: Untuk menemukan baris-baris data yang identik atau memiliki nilai yang sama di semua kolom. Data duplikat dapat menyebabkan bias dalam analisis dan pemodelan"""

# Cek jumlah data duplikat
print("Jumlah data duplikat:", df.duplicated().sum())

"""### Statistik Deskriptif: Untuk memahami karakteristik data dan mengidentifikasi pola serta tren"""

# Statistik deskriptif untuk data numerik
df.describe()

# Statistik deskriptif untuk data kategorikal
for column in df.select_dtypes(include=['object']).columns:
    print(f"\nStatistik Deskriptif untuk kolom '{column}':")
    print(df[column].value_counts())

"""### Cek Outlier
* Boxplot: Titik-titik di luar whisker boxplot menunjukkan potensi outlier. Outlier adalah data yang nilainya jauh berbeda dari data lainnya.
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Pilih kolom numerik yang ingin divisualisasikan
numerical_cols = ['year', 'rating', 'num_raters', 'num_reviews']

# Buat boxplot
plt.figure(figsize=(12, 6))
sns.boxplot(data=df[numerical_cols])
plt.title('Boxplot untuk Deteksi Outlier')
plt.xticks(rotation=45)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Pilih kolom numerik
numerical_cols = df.select_dtypes(include=np.number).columns.tolist()

# Menghitung matriks korelasi hanya untuk kolom numerik
correlation_matrix = df[numerical_cols].corr()

# Membuat heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Korelasi Heatmap (Kolom Numerik)')
plt.show()

"""# Data Preparation

* Menghapus duplikasi data
"""

# Hapus data duplikat
df.drop_duplicates(inplace=True)

# Cek kembali jumlah data duplikat setelah dihapus
print("Jumlah data duplikat setelah dihapus:", df.duplicated().sum())

"""* Drop kolom yag tidak relevan"""

# Asumsikan DataFrame 'df' sudah ada
print("Sebelum dihapus:", df.columns)  # Menampilkan kolom sebelum dihapus

# Drop kolom
df = df.drop(['release_date', 'review_url'], axis=1)

print("\nSetelah dihapus:", df.columns) # Menampilkan kolom setelah dihapus

"""* Encoding kolom genres"""

# # Mengambil genre pertama dari kolom "Genre"
# df['genres'] = df['genres'].apply(lambda x: x.split(';')[0] if isinstance(x, str) else x)

import pandas as pd
from sklearn.preprocessing import OneHotEncoder

# Inisialisasi OneHotEncoder
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # sparse=False for array output

# Fit dan transform data
encoded_data = encoder.fit_transform(df[['genres']])

# Buat DataFrame dari data yang sudah di-encode
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['genres']))

# Gabungkan DataFrame yang sudah di-encode dengan DataFrame asli
df = pd.concat([df, encoded_df], axis=1)

"""* Features Extraction dengan TF-IDF"""

# Representasi konten: title + genre + rating (dalam string)
df['features'] = (
    df['name'].astype(str) + ' ' +
    df['genres'].astype(str) + ' ' +
    df['rating'].astype(str)
)

# TF-IDF
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['features'])

# Menampilkan 5 baris pertama data
print(df.head())

df = df[df['name'].notnull()]  # Hilangkan baris dengan name kosong
df['name'] = df['name'].astype(str)  # Pastikan semua 'name' jadi string

df.info()

"""# Bangun Model

* Bangun Model: Content-Based Filtering
"""

# Cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Mapping judul
indices = pd.Series(df.index, index=df['name'].str.lower())

print("cosine_sim_matrix shape:", cosine_sim.shape)
print("df shape:", df.shape)

"""# Evaluasi model"""

def get_recommendations(title, cosine_sim_matrix, indices, top_n=10):
    title = title.lower()
    try:
        idx = indices[title]
        if isinstance(idx, (np.ndarray, pd.Series)):
            idx = int(idx[0]) if len(idx) > 0 else None
        else:
            idx = int(idx)
        if idx is None or idx >= cosine_sim_matrix.shape[0]:
            return []
    except KeyError:
        return []

    sim_scores = list(enumerate(cosine_sim_matrix[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n + 1]
    movie_indices = [i[0] for i in sim_scores if i[0] < len(df)]
    return df['name'].iloc[movie_indices].tolist()

# --- EVALUASI MODEL ---

# Split data
train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)
test_data['original_index'] = test_data.index
test_data = test_data.reset_index(drop=True)

cosine_sim_scores = []

def get_item_features(item_name, df):
    match = df[df['name'] == item_name]
    if not match.empty:
        row = match.iloc[0]
        return f"{row['name']} {row['genres']} {row['rating']}"
    return None

for index, row in test_data.iterrows():
    actual_item = row['name']
    recommended_items = get_recommendations(actual_item, cosine_sim, indices, top_n=10)

    if recommended_items:
        actual_features = tfidf.transform([f"{row['name']} {row['genres']} {row['rating']}"])

        recommended_features_list = [
            get_item_features(item, df) for item in recommended_items
        ]
        recommended_features_list = [f for f in recommended_features_list if f]

        if recommended_features_list:
            recommended_features = tfidf.transform(recommended_features_list)
            sim_scores = cosine_similarity(actual_features, recommended_features)
            avg_sim_score = np.mean(sim_scores)
            cosine_sim_scores.append(avg_sim_score)

# Hitung rata-rata skor similarity
if cosine_sim_scores:
    average_cosine_sim_score = np.mean(cosine_sim_scores)
    print(f"Average Cosine Similarity Score: {average_cosine_sim_score:.4f}")
else:
    print("No valid similarity scores could be computed.")

"""# Inferensi Model"""

def recommend_movies(title, top_n=10):
    title = title.lower()
    matches = indices[indices.index == title]

    if matches.empty:
        return f"Film '{title}' tidak ditemukan."

    idx = matches.iloc[0]  # ambil hanya satu index pertama
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n+1]
    movie_indices = [i[0] for i in sim_scores]

    return df[['name', 'genres', 'rating']].iloc[movie_indices]

# Contoh penggunaan
print("Rekomendasi untuk film seperti 'Avatar':")
print(recommend_movies("Avatar"))